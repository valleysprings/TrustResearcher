<div align="center">

# ğŸ”¬ Autonomous Research Agent

Elegant, multi-stage research ideation â€” from literature search to refined, distinct, wellâ€‘reviewed ideas â€” with clear logs, reproducible outputs, and a minimal setup.

<br/>

<img src="https://img.shields.io/badge/Python-3.8%2B-3776AB?logo=python&logoColor=white" alt="Python" />
<img src="https://img.shields.io/badge/Status-Active-34C759" alt="Status" />
<img src="https://img.shields.io/badge/Interface-CLI%20%26%20Web%20UI-8E8E93" alt="Interface" />

</div>

---

## ğŸ§© What It Does

The Autonomous Research Agent takes a topic and produces a polished set of research ideas by orchestrating a practical, literatureâ€‘aware pipeline:

- Retrieves relevant papers via the Semantic Scholar API with concurrency, rateâ€‘limiting, retries, deâ€‘duplication, and relevance/citation ranking.
- Builds a topicâ€‘anchored knowledge graph to maintain external memory during ideation.
- Overâ€‘generates ideas through planning, faceted decomposition, exploration, and selfâ€‘critique, then removes duplicates.
- Quickly evaluates candidates with weighted criteria and configurable distinctness thresholds.
- Checks distinctness against retrieved papers to avoid overlap.
- Runs reviewer, novelty, and proofreading agents in parallel and aggregates results into clean outputs.

The result is a structured JSON artifact (plus a humanâ€‘readable summary) and comprehensive logs of the process.

---

 

## âœ¨ Key Features

- Literatureâ€‘Guided Pipeline: highâ€‘signal retrieval before ideation, with sensible defaults and backoffs.
- Knowledge Graph Memory: lightweight `networkx` graph from topic (optionally from documents) to ground downstream reasoning.
- Robust Generation: planning + faceted decomposition + exploration variants + selfâ€‘critique with deâ€‘duplication.
- Fast Screening: weighted, configurable selection + distinctness thresholds.
- Parallel Deep Review: reviewer, novelty, and proofreading in parallel with consolidated reports.
- Web UI: interactive process visualization, multi-session control, and live logs.
- Reproducible Outputs: JSON + summary.txt with timing and costs; single consolidated LLM log per run.

---

## ğŸ—ï¸ Architecture

### 7-Pipeline System
The system uses a 7-pipeline architecture orchestrated by `ResearchPipelineOrchestrator`:

**Agents (7 specialized components):**
- **SemanticScholarAgent**: Literature search via Semantic Scholar API
- **IdeaGenerator**: Core idea generation with Graph-of-Thought reasoning
- **InternalSelector**: LLM-based idea deduplication and selection  
- **LiteratureSimilarityAgent**: TF-IDF similarity filtering against literature
- **ReviewerAgent**: Peer-review style evaluation
- **NoveltyAgent**: Novelty and significance assessment
- **Aggregator**: Result consolidation and portfolio analysis

**Pipeline Execution Order:**
1. **ValidationPipeline**: Pre-generation validation of system components
2. **LiteratureSearchPipeline**: Paper retrieval via Semantic Scholar API
3. **IdeaGenerationPipeline**: Idea generation with knowledge graph integration
4. **InternalSelectionPipeline**: LLM-based deduplication and initial filtering
5. **ExternalSelectionPipeline**: Literature similarity filtering using TF-IDF
6. **DetailedReviewPipeline**: Multi-agent review (reviewer + novelty + aggregator)
7. **FinalSelectionPipeline**: Final ranking and selection of top ideas
8. **PortfolioAnalysisPipeline**: Portfolio analysis and recommendations

### File Structure
```
autonomous-research-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __main__.py                   # Main entry point
â”‚   â”œâ”€â”€ main.py                       # Core application logic
â”‚   â”œâ”€â”€ ui_launcher.py                # Independent UI system
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base_agent.py             # Base agent interface
â”‚   â”‚   â”œâ”€â”€ aggregator.py             # Result aggregation
â”‚   â”‚   â”œâ”€â”€ idea_generator.py         # Core idea generation
â”‚   â”‚   â”œâ”€â”€ internal_selector.py      # LLM-based selection
â”‚   â”‚   â”œâ”€â”€ literature_similarity_agent.py  # TF-IDF similarity
â”‚   â”‚   â”œâ”€â”€ novelty_agent.py          # Novelty assessment
â”‚   â”‚   â”œâ”€â”€ reviewer_agent.py         # Peer review
â”‚   â”‚   â”œâ”€â”€ semantic_scholar_agent.py # Literature search
â”‚   â”‚   â””â”€â”€ idea_gen/                 # Idea generation modules
â”‚   â”‚       â”œâ”€â”€ base_agent.py         # Base agent for idea gen
â”‚   â”‚       â”œâ”€â”€ graph_of_thought.py   # GoT reasoning
â”‚   â”‚       â”œâ”€â”€ faceted_decomposition.py  # Multi-faceted analysis
â”‚   â”‚       â””â”€â”€ planning_module.py    # Strategic planning
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ research_pipeline_orchestrator.py  # Main orchestrator
â”‚   â”‚   â”œâ”€â”€ base_pipeline.py          # Pipeline interface
â”‚   â”‚   â”œâ”€â”€ validation_pipeline.py    # System validation
â”‚   â”‚   â”œâ”€â”€ literature_search_pipeline.py
â”‚   â”‚   â”œâ”€â”€ idea_generation_pipeline.py
â”‚   â”‚   â”œâ”€â”€ internal_selection_pipeline.py
â”‚   â”‚   â”œâ”€â”€ external_selection_pipeline.py
â”‚   â”‚   â”œâ”€â”€ detailed_review_pipeline.py
â”‚   â”‚   â”œâ”€â”€ final_selection_pipeline.py
â”‚   â”‚   â””â”€â”€ portfolio_analysis_pipeline.py
â”‚   â”œâ”€â”€ prompts/                      # All prompt templates
â”‚   â”‚   â”œâ”€â”€ interface_prompts.py      # Interface prompts
â”‚   â”‚   â”œâ”€â”€ literature_search/        # Literature search prompts
â”‚   â”‚   â”‚   â””â”€â”€ semantic_scholar_agent_prompts.py
â”‚   â”‚   â”œâ”€â”€ idea_generation/          # Idea generation prompts
â”‚   â”‚   â”‚   â”œâ”€â”€ idea_generator_prompts.py
â”‚   â”‚   â”‚   â”œâ”€â”€ faceted_decomposition_prompts.py
â”‚   â”‚   â”‚   â”œâ”€â”€ kg_builder_prompts.py
â”‚   â”‚   â”‚   â””â”€â”€ planning_module_prompts.py
â”‚   â”‚   â”œâ”€â”€ selection/                # Selection prompts
â”‚   â”‚   â”‚   â””â”€â”€ idea_selector_prompts.py
â”‚   â”‚   â””â”€â”€ detailed_review/          # Review prompts
â”‚   â”‚       â”œâ”€â”€ reviewer_agent_prompts.py
â”‚   â”‚       â””â”€â”€ novelty_agent_prompts.py
â”‚   â”œâ”€â”€ knowledge_graph/
â”‚   â”‚   â”œâ”€â”€ kg_builder.py             # Knowledge graph construction
â”‚   â”‚   â””â”€â”€ graph_utils.py            # Graph utilities
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ async_utils.py            # Async utilities
â”‚       â”œâ”€â”€ config.py                 # Configuration management
â”‚       â”œâ”€â”€ debug_logger.py           # Logging system
â”‚       â”œâ”€â”€ llm_interface.py          # LLM client
â”‚       â”œâ”€â”€ phase_timer.py            # Performance tracking
â”‚       â”œâ”€â”€ pregen_validation.py      # Pre-generation validation
â”‚       â”œâ”€â”€ session_manager.py        # Session management
â”‚       â”œâ”€â”€ text_utils.py             # Text processing utilities
â”‚       â”œâ”€â”€ token_cost_tracker.py     # Token and cost tracking
â”‚       â””â”€â”€ web_ui.py                 # Gradio interface
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ agent_config.yaml             # Configuration
â””â”€â”€ outputs/, logs/, llm_logs/, idea_logs/, sessions/ (runtime)
```

### Pipeline Flow
1. **Literature Search** â†’ Academic paper retrieval (50 papers are good enough to generate mid-to-high-quality ideas)
2. **Knowledge Graph Construction** â†’ Build topic-anchored knowledge graph from literature
3. **Idea Generation** â†’ Multi-method idea generation (planning + faceted decomposition + GoT reasoning + variants + self-critique)
4. **Internal Selection** â†’ LLM deduplication and filtering
5. **External Selection** â†’ TF-IDF / Embedding-based similarity against literature
6. **Detailed Review** â†’ Multi-agent evaluation (reviewer + novelty)
7. **Final Selection** â†’ Top idea ranking
8. **Portfolio Analysis** â†’ Summary and recommendations


---

## ğŸ§­ Pipeline

![pipeline](pipeline.png)

---

## âš™ï¸ Installation

Requirements
- Python 3.8+
- Network access for the model API and Semantic Scholar

*Tip: use a virtual environment (venv or conda) to isolate dependencies.*

Install
```bash
pip install -e .
```

Configure your credentials in `configs/custom_pipeline_example.yaml` and rename to `agent_config.yaml`:

---

## ğŸ–¼ï¸ Case Study: Web UI in Action

Hereâ€™s what the interactive Web UI looks like when running a research session:

![case_study_ui](casestudy.png)

---

## ğŸš€ Quick Start

* CLI

```bash
# help
python -m src --help

# full pipeline (ensure configs/agent_config.yaml is set)
python -m src --topic "Design scalable and robust algorithms for the k-truss breaking problem that bypass global trussness updates via localized, incremental, and approximation methods, enabling near-real-time interventions on large-scale graphs." --num_ideas 2 --debug
```



* Web UI

```bash
# process visualization UI
python -m src.ui_launcher --process-ui

# set UI host (default: localhost; use 0.0.0.0 for LAN)
python -m src.ui_launcher --process-ui --process-host 0.0.0.0

# set UI port (default: 7860)
python -m src.ui_launcher --process-ui --process-port 7861
```

---

## ğŸ“¤ Outputs & ğŸ“œ Logs

- Results: `outputs/{topic}_{timestamp}.json` with the complete pipeline output.
- Run logs: `logs/session_YYYYMMDD_HHMMSS.log` (single file per run).
- LLM logs: `llm_logs/{topic}_{timestamp}.jsonl` (All interaction from agents per run with token & cost stats).
- Idea logs: `idea_logs/ideas_{timestamp}.json` (all generated ideas for each refinement stage).

---

## ğŸ§¯ Troubleshooting

- Always run as a module: `python -m src ...` (avoid `python src/main.py`).
- Ensure write permissions for `outputs/`, `logs/`, and `llm_logs/`.

 
